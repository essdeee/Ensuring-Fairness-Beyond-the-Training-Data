{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from meta_algo import MetaAlgorithm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import voting_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_proportions is only a helper function for plotting\n",
    "def show_proportions(X, sensitive_features, y_pred, y=None, description=\"Demographic Parity\", plot_row_index=1):\n",
    "    print(\"\\n\" + description)\n",
    "    plt.figure(plot_row_index)\n",
    "    plt.title(description)\n",
    "    plt.ylabel(\"P[recidivism predicted | conditions]\")\n",
    "    \n",
    "    indices = {}\n",
    "    positive_indices = {}\n",
    "    negative_indices = {}\n",
    "    recidivism_count = {}\n",
    "    recidivism_pct = {}\n",
    "    groups = np.unique(sensitive_features.values)\n",
    "    n_groups = len(groups)\n",
    "    max_group_length = max([len(group) for group in groups])\n",
    "    color = cm.rainbow(np.linspace(0,1,n_groups))\n",
    "    x_tick_labels_basic = []\n",
    "    x_tick_labels_by_label = []\n",
    "    for index, group in enumerate(groups):\n",
    "        indices[group] = sensitive_features.index[sensitive_features == group]\n",
    "        recidivism_count[group] = sum(y_pred[indices[group]])\n",
    "        recidivism_pct[group] = recidivism_count[group]/len(indices[group])\n",
    "        print(\"P[recidivism predicted | {}]                {}= {}\".format(group, \" \"*(max_group_length-len(group)), recidivism_pct[group]))\n",
    "    \n",
    "        plt.bar(index + 1, recidivism_pct[group], color=color[index])\n",
    "        x_tick_labels_basic.append(group)\n",
    "    \n",
    "        if y is not None:\n",
    "            positive_indices[group] = sensitive_features.index[(sensitive_features == group) & (y == 1)]\n",
    "            negative_indices[group] = sensitive_features.index[(sensitive_features == group) & (y == 0)]\n",
    "            prob_1 = sum(y_pred[positive_indices[group]])/len(positive_indices[group])\n",
    "            prob_0 = sum(y_pred[negative_indices[group]])/len(negative_indices[group])\n",
    "            print(\"P[recidivism predicted | {}, recidivism]    {}= {}\".format(group, \" \"*(max_group_length-len(group)) , prob_1))\n",
    "            print(\"P[recidivism predicted | {}, no recidivism] {}= {}\".format(group, \" \"*(max_group_length-len(group)), prob_0))\n",
    "\n",
    "            plt.bar(n_groups + 1 + 2 * index, prob_1, color=color[index])\n",
    "            plt.bar(n_groups + 2 + 2 * index, prob_0, color=color[index])\n",
    "            x_tick_labels_by_label.extend([\"{} recidivism\".format(group), \"{} no recidivism\".format(group)])\n",
    "    \n",
    "    x_tick_labels = x_tick_labels_basic + x_tick_labels_by_label\n",
    "    plt.xticks(range(1, len(x_tick_labels)+1), x_tick_labels, rotation=45, horizontalalignment=\"right\")\n",
    "\n",
    "dataset_used = 'compas'\n",
    "\n",
    "if(dataset_used == 'compas'):\n",
    "    compas_train = pd.read_csv('./../../data/compas_train.csv')\n",
    "    compas_val = pd.read_csv('./../../data/compas_val.csv')\n",
    "    compas_test = pd.read_csv('./../../data/compas_test.csv')\n",
    "\n",
    "    y_train = compas_train.pop('two_year_recid') \n",
    "    y_test = compas_test.pop('two_year_recid')\n",
    "    sensitive_features_train = compas_train['race']\n",
    "    sensitive_features_test = compas_test['race']\n",
    "    X_train = compas_train\n",
    "    X_test = compas_test\n",
    "    \n",
    "    X_train = X_train.drop('Unnamed: 0', axis=1)\n",
    "    X_test = X_test.drop('Unnamed: 0', axis=1)\n",
    "    \n",
    "    sensitive_features_train = sensitive_features_train.replace(0, 'African-American')\n",
    "    sensitive_features_train = sensitive_features_train.replace(1, 'Caucasian')\n",
    "    sensitive_features_test = sensitive_features_test.replace(0, 'African-American')\n",
    "    sensitive_features_test = sensitive_features_test.replace(1, 'Caucasian')\n",
    "    \n",
    "elif(dataset_used == 'adult'):\n",
    "    adult_train = pd.read_csv('./../../data/adult_train.csv')\n",
    "    adult_val = pd.read_csv('./../../data/adult_val.csv')\n",
    "    adult_test = pd.read_csv('./../../data/adult_test.csv')\n",
    "\n",
    "    y_train = adult_train.pop('Income Binary') \n",
    "    y_test = adult_test.pop('Income Binary')\n",
    "    sensitive_features_train = adult_train['sex']\n",
    "    sensitive_features_test = adult_test['sex']\n",
    "    X_train = adult_train\n",
    "    X_test = adult_test\n",
    "    \n",
    "    X_train = X_train.drop('Unnamed: 0', axis=1)\n",
    "    X_test = X_test.drop('Unnamed: 0', axis=1)\n",
    "    \n",
    "    sensitive_features_train = sensitive_features_train.replace(0, 'Female')\n",
    "    sensitive_features_train = sensitive_features_train.replace(1, 'Male')\n",
    "    sensitive_features_test = sensitive_features_test.replace(0, 'Female')\n",
    "    sensitive_features_test = sensitive_features_test.replace(1, 'Male')\n",
    "    \n",
    "else:\n",
    "    print('Invalid dataset_used variable.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'hypotheses_ensemble_2020-04-21_14:10:07.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0d8282acf068>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mHYPOTHESIS_FILE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"hypotheses_ensemble_2020-04-21_14:10:07.pkl\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mensemble_hyp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHYPOTHESIS_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'hypotheses_ensemble_2020-04-21_14:10:07.pkl'"
     ]
    }
   ],
   "source": [
    "HYPOTHESIS_FILE = \"hypotheses_ensemble_2020-04-21_14:10:07.pkl\"\n",
    "ensemble_hyp = pickle.load(open(HYPOTHESIS_FILE, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_proportions(X_test, sensitive_features_test, ensemble_hyp.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(ensemble_hyp.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "show_proportions(X_test, sensitive_features_test, logreg.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logreg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-cbc8335b1fe8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'logreg' is not defined"
     ]
    }
   ],
   "source": [
    "accuracy_score(logreg.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIST_FILE = \"ensemble_ensemble_adult500split1.pkl\"\n",
    "list_hyp = pickle.load(open(LIST_FILE, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('./../../data/processed/adult/adult_train1_X.csv')\n",
    "X_test = pd.read_csv('./../../data/processed/adult/adult_test1_X.csv')\n",
    "y_train = pd.read_csv('./../../data/processed/adult/adult_train1_y.csv')\n",
    "y_test = pd.read_csv('./../../data/processed/adult/adult_test1_y.csv')\n",
    "\n",
    "y_train = y_train['income']\n",
    "y_test = y_test['income']\n",
    "\n",
    "sensitive_features_train = X_train['sex']\n",
    "sensitive_features_test = X_test['sex']\n",
    "\n",
    "sensitive_features_train[sensitive_features_train <= 0] = 0\n",
    "sensitive_features_train[sensitive_features_train > 0] = 1\n",
    "sensitive_features_train = sensitive_features_train.reset_index(drop=True)\n",
    "\n",
    "sensitive_features_test[sensitive_features_test <= 0] = 0\n",
    "sensitive_features_test[sensitive_features_test > 0] = 1\n",
    "sensitive_features_test = sensitive_features_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fairness_checking] *",
   "language": "python",
   "name": "conda-env-fairness_checking-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
