{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.algorithms.preprocessing.reweighing import Reweighing\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_arr = []\n",
    "X_test_arr = []\n",
    "y_train_arr = []\n",
    "y_test_arr = []\n",
    "sensitive_features_train_arr = []\n",
    "sensitive_features_test_arr = []\n",
    "\n",
    "for i in range(5):\n",
    "    X_train = pd.read_csv('./../../data/processed/adult/adult_train{}_X.csv'.format(i + 1))\n",
    "    X_test = pd.read_csv('./../../data/processed/adult/adult_test{}_X.csv'.format(i + 1))\n",
    "    y_train = pd.read_csv('./../../data/processed/adult/adult_train{}_y.csv'.format(i + 1))\n",
    "    y_test = pd.read_csv('./../../data/processed/adult/adult_test{}_y.csv'.format(i + 1))\n",
    "\n",
    "    y_train = y_train['income']\n",
    "    y_test = y_test['income']\n",
    "    \n",
    "    sensitive_features_train = X_train['sex']\n",
    "    sensitive_features_test = X_test['sex']\n",
    "\n",
    "    sensitive_features_train[sensitive_features_train <= 0] = 0\n",
    "    sensitive_features_train[sensitive_features_train > 0] = 1\n",
    "    sensitive_features_train = sensitive_features_train.reset_index(drop=True)\n",
    "    \n",
    "    sensitive_features_test[sensitive_features_test <= 0] = 0\n",
    "    sensitive_features_test[sensitive_features_test > 0] = 1\n",
    "    sensitive_features_test = sensitive_features_test.reset_index(drop=True)\n",
    "    \n",
    "    X_train_arr.append(X_train)\n",
    "    X_test_arr.append(X_test)\n",
    "    y_train_arr.append(y_train)\n",
    "    y_test_arr.append(y_test)\n",
    "    sensitive_features_train_arr.append(sensitive_features_train)\n",
    "    sensitive_features_test_arr.append(sensitive_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_arr[0]\n",
    "y_train = y_train_arr[0]\n",
    "X_test = X_test_arr[0]\n",
    "y_test = y_test_arr[0]\n",
    "sensitive_features_test = sensitive_features_test_arr[0]\n",
    "\n",
    "X_train['income'] = y_train\n",
    "X_test['income'] = y_test\n",
    "\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset object\n",
    "binary = BinaryLabelDataset(1, 0, df=X_train, label_names=['income'], protected_attribute_names=['sex'])\n",
    "binary_test = BinaryLabelDataset(1, 0, df=X_test, label_names=['income'], protected_attribute_names=['sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "               privileged_groups=privileged_groups)\n",
    "RW.fit(binary)\n",
    "dataset_transf_train = RW.transform(binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_transf = StandardScaler()\n",
    "X_train = scale_transf.fit_transform(dataset_transf_train.features)\n",
    "y_train = dataset_transf_train.labels.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sam/anaconda3/envs/fairness_checking/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmod = LogisticRegression()\n",
    "lmod.fit(X_train, y_train,\n",
    "        sample_weight=dataset_transf_train.instance_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_transf_test_pred = binary_test.copy(deepcopy=True)\n",
    "X_test = scale_transf.fit_transform(dataset_transf_test_pred.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8341584158415841"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(lmod.predict(X_test), y_test_arr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "def evaluate_fairness(y_true, y_pred, sensitive_features):\n",
    "    \"\"\"\n",
    "    Evaluates fairness of the final majority vote classifier over T_inner hypotheses\n",
    "    on the test set.\n",
    "    #NOTE: defined in the meta_algo file, but we chose:\n",
    "    a0 := African-American (COMPAS), Female (Adult)\n",
    "    a1 := Caucasian (COMPAS), Male (Adult)\n",
    "\n",
    "    :return: list. subgroups in sensitive_features.\n",
    "    :return: list, dict, dict. groups is a list of the sensitive features in the dataset. \n",
    "    group_metrics is a dictionary containing dictionaries that have Delta_dp, Delta_eoy0, \n",
    "    and Delta_eoy1 for each group. gaps is a dictionary that contains the fairness gap\n",
    "    for dp, eo_y0 and eo_y1.\n",
    "    \"\"\"\n",
    "    groups = np.unique(sensitive_features.values)\n",
    "    pos_count = {}\n",
    "    dp_pct = {}\n",
    "    eo_y0_pct = {}\n",
    "    eo_y1_pct = {}\n",
    "\n",
    "    for index, group in enumerate(groups):\n",
    "        # Demographic Parity\n",
    "        indices = {}\n",
    "        indices[group] = sensitive_features.index[sensitive_features == group]\n",
    "        dp_pct[group] = sum(y_pred[indices[group]])/len(indices[group])\n",
    "\n",
    "        # Equalized Odds\n",
    "        y1_indices = {}\n",
    "        y0_indices = {}\n",
    "        y1_indices[group] = sensitive_features.index[(sensitive_features == group) & (y_true == 1)]\n",
    "        y0_indices[group] = sensitive_features.index[(sensitive_features == group) & (y_true == 0)]\n",
    "        eo_y0_pct[group] = sum(y_pred[y0_indices[group]])/len(y0_indices[group])   \n",
    "        eo_y1_pct[group] = sum(y_pred[y1_indices[group]])/len(y1_indices[group])\n",
    "\n",
    "    gaps = {}\n",
    "    group_metrics = {} # a dictionary of dictionaries\n",
    "\n",
    "    gaps['dp'] = abs(dp_pct[groups[0]] - dp_pct[groups[1]])\n",
    "    gaps['eo_y0'] = abs(eo_y0_pct[groups[0]] - eo_y0_pct[groups[1]])\n",
    "    gaps['eo_y1'] = abs(eo_y1_pct[groups[0]] - eo_y1_pct[groups[1]])\n",
    "    group_metrics['dp'] = dp_pct\n",
    "    group_metrics['eo_y0'] = eo_y0_pct\n",
    "    group_metrics['eo_y1'] = eo_y1_pct\n",
    "\n",
    "    return groups, group_metrics, gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]),\n",
       " {'dp': {0.0: 0.5671140939597316, 1.0: 0.24528301886792453},\n",
       "  'eo_y0': {0.0: 0.26174496644295303, 1.0: 0.02666666666666667},\n",
       "  'eo_y1': {0.0: 0.87248322147651, 1.0: 0.7741935483870968}},\n",
       " {'dp': 0.32183107509180703,\n",
       "  'eo_y0': 0.23507829977628636,\n",
       "  'eo_y1': 0.09828967308941328})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_fairness(lmod.predict(X_test), y_test_arr[0], sensitive_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit( X_train_arr[0], y_train_arr[0])\n",
    "\n",
    "evaluate_fairness(logreg.predict(X_test_arr[0]), y_test_arr[0], sensitive_features_test_arr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(logreg.predict(X_test_arr[0]), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.predict(X_test_arr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
