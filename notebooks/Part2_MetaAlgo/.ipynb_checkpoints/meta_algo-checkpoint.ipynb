{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset_used = 'compas'\n",
    "\n",
    "if(dataset_used == 'compas'):\n",
    "    compas_train = pd.read_csv('./../../data/compas_train.csv')\n",
    "    compas_val = pd.read_csv('./../../data/compas_val.csv')\n",
    "    compas_test = pd.read_csv('./../../data/compas_test.csv')\n",
    "\n",
    "    y_train = compas_train.pop('two_year_recid') \n",
    "    y_test = compas_test.pop('two_year_recid')\n",
    "    sensitive_features_train = compas_train['race']\n",
    "    sensitive_features_test = compas_test['race']\n",
    "    X_train = compas_train\n",
    "    X_test = compas_test\n",
    "    \n",
    "    sensitive_features_train = sensitive_features_train.replace(0, 'African-American')\n",
    "    sensitive_features_train = sensitive_features_train.replace(1, 'Caucasian')\n",
    "    sensitive_features_test = sensitive_features_test.replace(0, 'African-American')\n",
    "    sensitive_features_test = sensitive_features_test.replace(1, 'Caucasian')\n",
    "    \n",
    "elif(dataset_used == 'adult'):\n",
    "    adult_train = pd.read_csv('./../../data/adult_train.csv')\n",
    "    adult_val = pd.read_csv('./../../data/adult_val.csv')\n",
    "    adult_test = pd.read_csv('./../../data/adult_test.csv')\n",
    "\n",
    "    y_train = adult_train.pop('Income Binary') \n",
    "    y_test = adult_test.pop('Income Binary')\n",
    "    sensitive_features_train = adult_train['sex']\n",
    "    sensitive_features_test = adult_test['sex']\n",
    "    X_train = adult_train\n",
    "    X_test = adult_test\n",
    "    \n",
    "    sensitive_features_train = sensitive_features_train.replace(0, 'Female')\n",
    "    sensitive_features_train = sensitive_features_train.replace(1, 'Male')\n",
    "    sensitive_features_test = sensitive_features_test.replace(0, 'Female')\n",
    "    sensitive_features_test = sensitive_features_test.replace(1, 'Male')\n",
    "    \n",
    "else:\n",
    "    print('Invalid dataset_used variable.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Unnamed: 0                  7796.0\n",
       " sex                            0.0\n",
       " race                           0.0\n",
       " age_cat=25 to 45               1.0\n",
       " age_cat=Greater than 45        0.0\n",
       " age_cat=Less than 25           0.0\n",
       " priors_count=0                 0.0\n",
       " priors_count=1 to 3            1.0\n",
       " priors_count=More than 3       0.0\n",
       " c_charge_degree=F              1.0\n",
       " c_charge_degree=M              0.0\n",
       " Name: 0, dtype: float64,\n",
       " 1.0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.loc[0], y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "\n",
    "def log_loss_function(pred, y, weights=None, eps=1e-15):\n",
    "    n = len(y)\n",
    "\n",
    "    pred = np.clip(pred, eps, 1 - eps)\n",
    "    class1_cost = -y * np.log(pred)\n",
    "    class0_cost = -(1 - y) * np.log(1 - pred)\n",
    "    loss = class1_cost + class0_cost\n",
    "\n",
    "    if(weights.all()):\n",
    "        loss = np.dot(weights, loss)\n",
    "    else:\n",
    "        loss = loss.sum() / n\n",
    "\n",
    "    return loss\n",
    "\n",
    "def log_loss_grad_w(pred, y, eps=1e-15):\n",
    "    n = len(y)\n",
    "\n",
    "    pred = np.clip(pred, eps, 1 - eps)\n",
    "    class1_cost = -y * np.log(pred)\n",
    "    class0_cost = -(1 - y) * np.log(1 - pred)\n",
    "    loss = class1_cost + class0_cost\n",
    "    loss = loss.to_numpy()\n",
    "\n",
    "    return loss\n",
    "\n",
    "def zero_one_loss_grad_w(pred, y):\n",
    "    loss_vec = []\n",
    "    for (i,y_true) in enumerate(y):\n",
    "        if(y_true == pred[i]):\n",
    "            loss_vec.append(0)\n",
    "        else:\n",
    "            loss_vec.append(1)\n",
    "            \n",
    "    return np.asarray(loss_vec)\n",
    "    \n",
    "\n",
    "def project_W(w):\n",
    "    x = cp.Variable(len(w))\n",
    "    objective = cp.Minimize(0.5 * cp.sum_squares(w - x))\n",
    "    constraints = [0 <= x, x <= 1, cp.sum(x) == 1]\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve()\n",
    "    \n",
    "    return x.value\n",
    "\n",
    "def bayesian_oracle(w):\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000213\n",
      "0.9999999999999757\n",
      "0.9999999999999662\n",
      "1.0000000000000229\n",
      "1.0000000000000224\n",
      "1.0000000000000135\n",
      "1.0000000000000198\n",
      "1.0000000000000053\n",
      "1.000000000000007\n",
      "0.9999999999999789\n"
     ]
    }
   ],
   "source": [
    "# Meta Algo\n",
    "from fairlearn.reductions import ExponentiatedGradient, DemographicParity, EqualizedOdds\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics\n",
    "\n",
    "constraint_used = 'dp' # dp, eo\n",
    "w = np.full((X_train.shape[0],), 1/X_train.shape[0])\n",
    "\n",
    "if(constraint_used =='dp'):\n",
    "    expgrad_X = ExponentiatedGradient(\n",
    "        LogisticRegression(solver='liblinear', fit_intercept=True, class_weight='balanced'),\n",
    "        constraints=DemographicParity(),\n",
    "        eps=0.01,\n",
    "        nu=1e-6)\n",
    "elif(constraint_used == 'eo'):\n",
    "    expgrad_X = ExponentiatedGradient(\n",
    "        LogisticRegression(solver='liblinear', fit_intercept=True, class_weight='balanced'),\n",
    "        constraints=EqualizedOdds(),\n",
    "        eps=0.01,\n",
    "        nu=1e-6)\n",
    "\n",
    "expgrad_X.fit(X_train, y_train, sensitive_features=sensitive_features_train, sample_weight=w)\n",
    "\n",
    "T = 10\n",
    "eta = 1/np.sqrt(2*T)\n",
    "w = np.full((X_train.shape[0],), 1/X_train.shape[0])\n",
    "hs = []\n",
    "for t in range(T):\n",
    "    w += eta * zero_one_loss_grad_w(expgrad_X.predict(X_train), y_train)\n",
    "    w = project_W(w)\n",
    "    print(w.sum())\n",
    "    # h_t = M(w_t) TODO: BAYESIAN ORACLE STEP."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
