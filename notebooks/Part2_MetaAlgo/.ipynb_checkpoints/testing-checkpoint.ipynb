{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from meta_algo import MetaAlgorithm\n",
    "\n",
    "dataset_used = 'compas'\n",
    "\n",
    "if(dataset_used == 'compas'):\n",
    "    compas_train = pd.read_csv('./../../data/compas_train.csv')\n",
    "    compas_val = pd.read_csv('./../../data/compas_val.csv')\n",
    "    compas_test = pd.read_csv('./../../data/compas_test.csv')\n",
    "\n",
    "    y_train = compas_train.pop('two_year_recid') \n",
    "    y_test = compas_test.pop('two_year_recid')\n",
    "    sensitive_features_train = compas_train['race']\n",
    "    sensitive_features_test = compas_test['race']\n",
    "    X_train = compas_train\n",
    "    X_test = compas_test\n",
    "    \n",
    "    sensitive_features_train = sensitive_features_train.replace(0, 'African-American')\n",
    "    sensitive_features_train = sensitive_features_train.replace(1, 'Caucasian')\n",
    "    sensitive_features_test = sensitive_features_test.replace(0, 'African-American')\n",
    "    sensitive_features_test = sensitive_features_test.replace(1, 'Caucasian')\n",
    "    \n",
    "elif(dataset_used == 'adult'):\n",
    "    adult_train = pd.read_csv('./../../data/adult_train.csv')\n",
    "    adult_val = pd.read_csv('./../../data/adult_val.csv')\n",
    "    adult_test = pd.read_csv('./../../data/adult_test.csv')\n",
    "\n",
    "    y_train = adult_train.pop('Income Binary') \n",
    "    y_test = adult_test.pop('Income Binary')\n",
    "    sensitive_features_train = adult_train['sex']\n",
    "    sensitive_features_test = adult_test['sex']\n",
    "    X_train = adult_train\n",
    "    X_test = adult_test\n",
    "    \n",
    "    sensitive_features_train = sensitive_features_train.replace(0, 'Female')\n",
    "    sensitive_features_train = sensitive_features_train.replace(1, 'Male')\n",
    "    sensitive_features_test = sensitive_features_test.replace(0, 'Female')\n",
    "    sensitive_features_test = sensitive_features_test.replace(1, 'Male')\n",
    "    \n",
    "else:\n",
    "    print('Invalid dataset_used variable.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4625769777356703"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(y_train)/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6818181818181818"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(class_weight='balanced')\n",
    "logreg.fit(X_train, y_train)\n",
    "accuracy_score(logreg.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitive_features_train\n",
    "sensitive_features_train = sensitive_features_train.replace('African-American', 0)\n",
    "sensitive_features_train = sensitive_features_train.replace('Caucasian', 1)\n",
    "sensitive_features_train = sensitive_features_train.replace('Female', 0)\n",
    "sensitive_features_train = sensitive_features_train.replace('Male', 1)\n",
    "\n",
    "a_indices = dict()\n",
    "a_indices['a0'] = sensitive_features_train.index[sensitive_features_train.eq(0)].tolist()\n",
    "a_indices['a1'] = sensitive_features_train.index[sensitive_features_train.eq(1)].tolist()\n",
    "a_indices['all'] = sensitive_features_train.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "469.0"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = logreg.predict(X_train)\n",
    "pred[a_indices['a0']].sum()\n",
    "pred[a_indices['a1']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as ran\n",
    "\n",
    "r = [ran.random() for i in range(0,len(X_train))]\n",
    "s = sum(r)\n",
    "r = [ i/s for i in r ]\n",
    "r = np.asarray(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_a0_sum = r[a_indices['a0']].sum()\n",
    "weights_a1_sum = r[a_indices['a1']].sum()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.20757186e-04 2.66458001e-04 3.00645282e-04 6.17232963e-05\n",
      " 3.69118750e-04 4.00894134e-04 3.11757755e-04 5.69711532e-05\n",
      " 1.55998743e-04 1.84652711e-04 3.01910659e-04 3.84604693e-04\n",
      " 3.37735422e-04 1.47197169e-04 1.65657572e-04 4.32352028e-04\n",
      " 1.38302444e-04 4.07375689e-04 2.21382790e-04 9.95643424e-05\n",
      " 2.74748779e-04 2.79040410e-04 2.76727249e-04 4.57120439e-04\n",
      " 1.82858720e-05]\n",
      "[3.69670041e-04 4.46198568e-04 5.03447048e-04 6.17232963e-05\n",
      " 6.18109634e-04 6.71319260e-04 3.11757755e-04 9.54013272e-05\n",
      " 2.61228470e-04 3.09211114e-04 3.01910659e-04 6.44041697e-04\n",
      " 5.65556527e-04 2.46489749e-04 2.77402709e-04 7.23997233e-04\n",
      " 2.31595043e-04 6.82172981e-04 3.70717650e-04 1.66725963e-04\n",
      " 4.60081931e-04 2.79040410e-04 2.76727249e-04 7.65473299e-04\n",
      " 1.82858720e-05]\n",
      "[2.20757186e-04 2.66458001e-04 3.00645282e-04 1.53225546e-04\n",
      " 3.69118750e-04 4.00894134e-04 7.73925811e-04 5.69711532e-05\n",
      " 1.55998743e-04 1.84652711e-04 7.49480801e-04 3.84604693e-04\n",
      " 3.37735422e-04 1.47197169e-04 1.65657572e-04 4.32352028e-04\n",
      " 1.38302444e-04 4.07375689e-04 2.21382790e-04 9.95643424e-05\n",
      " 2.74748779e-04 6.92706348e-04 6.86964019e-04 4.57120439e-04\n",
      " 4.53939256e-05]\n"
     ]
    }
   ],
   "source": [
    "weights = r.copy()\n",
    "a0_mask = np.zeros(len(weights), dtype=bool)\n",
    "a0_mask[a_indices['a0']] = True\n",
    "a1_mask = np.zeros(len(weights), dtype=bool)\n",
    "a1_mask[a_indices['a1']] = True\n",
    "\n",
    "print(weights[:25])\n",
    "weights_div = np.true_divide(weights, weights_a0_sum, where=a0_mask)\n",
    "print(weights[:25])\n",
    "weights = np.true_divide(weights_div, weights_a1_sum, where=a1_mask)\n",
    "print(weights[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4221"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_indices['a1'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6818181818181818\n"
     ]
    }
   ],
   "source": [
    "algo = MetaAlgorithm(T=10, T_1=10)\n",
    "algo.meta_algorithm(X_train, y_train, sensitive_features_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
