{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fairness(y_true, y_pred, sensitive_features):\n",
    "        \"\"\"\n",
    "        Evaluates fairness of the final majority vote classifier over T_inner hypotheses\n",
    "        on the test set.\n",
    "        #NOTE: defined in the meta_algo file, but we chose:\n",
    "        a0 := African-American (COMPAS), Female (Adult)\n",
    "        a1 := Caucasian (COMPAS), Male (Adult)\n",
    "\n",
    "        :return: list. subgroups in sensitive_features.\n",
    "        :return: dict. recidivism_pct for each group.\n",
    "        \"\"\"\n",
    "        groups = np.unique(sensitive_features.values)\n",
    "        pos_count = {}\n",
    "        dp_pct = {}\n",
    "        eo_y0_pct = {}\n",
    "        eo_y1_pct = {}\n",
    "        \n",
    "        for index, group in enumerate(groups):\n",
    "            # Demographic Parity\n",
    "            indices = {}\n",
    "            indices[group] = sensitive_features.index[sensitive_features == group]\n",
    "            dp_pct[group] = sum(y_pred[indices[group]])/len(indices[group])\n",
    "\n",
    "            # Equalized Odds\n",
    "            y1_indices = {}\n",
    "            y0_indices = {}\n",
    "            y1_indices[group] = sensitive_features.index[(sensitive_features == group) & (y_true == 1)]\n",
    "            y0_indices[group] = sensitive_features.index[(sensitive_features == group) & (y_true == 0)]\n",
    "            eo_y0_pct[group] = sum(y_pred[y0_indices[group]])/len(y0_indices[group])   \n",
    "            eo_y1_pct[group] = sum(y_pred[y1_indices[group]])/len(y1_indices[group])\n",
    "        \n",
    "        gaps = {}\n",
    "        group_metrics = {} # a dictionary of dictionaries\n",
    "\n",
    "        gaps['dp'] = abs(dp_pct[groups[0]] - dp_pct[groups[1]])\n",
    "        gaps['eo_y0'] = abs(eo_y0_pct[groups[0]] - eo_y0_pct[groups[1]])\n",
    "        gaps['eo_y1'] = abs(eo_y1_pct[groups[0]] - eo_y1_pct[groups[1]])\n",
    "        group_metrics['dp'] = dp_pct\n",
    "        group_metrics['eo_y0'] = eo_y0_pct\n",
    "        group_metrics['eo_y1'] = eo_y1_pct\n",
    "        \n",
    "        return groups, group_metrics, gaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compas Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compas_train = pd.read_csv('./data/processed/compas/compas_train1_X.csv')\n",
    "compas_test = pd.read_csv('./data/processed/compas/compas_test1_X.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compas_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = compas_train.pop('two_year_recid') \n",
    "y_test = compas_test.pop('two_year_recid')\n",
    "sensitive_features_train = compas_train['race']\n",
    "sensitive_features_test = compas_test['race']\n",
    "X_train = compas_train\n",
    "X_test = compas_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitive_features_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "groups, group_metrics, gaps = evaluate_fairness(y_test, y_pred, sensitive_features_test)\n",
    "\n",
    "print(\"Logistic Regression Accuracy: \" + str(accuracy_score(y_pred, y_test)))\n",
    "\n",
    "# Demographic Parity\n",
    "for group in groups:\n",
    "      print(\"P[h(X) = 1 | {}] = {}\".format(group, group_metrics['dp'][group]))\n",
    "print(\"Delta_dp = {}\".format(gaps['dp']))\n",
    "\n",
    "# Equalized Odds\n",
    "for group in groups:\n",
    "    print(\"P[h(X) = 1 | A = {}, Y = 1] = {}\".format(group, group_metrics['eo_y1'][group]))\n",
    "    print(\"P[h(X) = 1 | A = {}, Y = 0] = {}\".format(group, group_metrics['eo_y0'][group]))\n",
    "print(\"Delta_eo1 = {}\".format(gaps['eo_y1']))\n",
    "print(\"Delta_eo0 = {}\".format(gaps['eo_y0']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "groups, group_metrics, gaps = evaluate_fairness(y_test, y_pred, sensitive_features_test)\n",
    "\n",
    "print(\"Random Forest Accuracy: \" + str(accuracy_score(y_pred, y_test)))\n",
    "\n",
    "# Demographic Parity\n",
    "for group in groups:\n",
    "      print(\"P[h(X) = 1 | {}] = {}\".format(group, group_metrics['dp'][group]))\n",
    "print(\"Delta_dp = {}\".format(gaps['dp']))\n",
    "\n",
    "# Equalized Odds\n",
    "for group in groups:\n",
    "    print(\"P[h(X) = 1 | A = {}, Y = 1] = {}\".format(group, group_metrics['eo_y1'][group]))\n",
    "    print(\"P[h(X) = 1 | A = {}, Y = 0] = {}\".format(group, group_metrics['eo_y0'][group]))\n",
    "print(\"Delta_eo1 = {}\".format(gaps['eo_y1']))\n",
    "print(\"Delta_eo0 = {}\".format(gaps['eo_y0']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adult Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_X = pd.read_csv('./data/adult_X.csv')\n",
    "adult_y = pd.read_csv('./data/adult_y.csv')\n",
    "\n",
    "adult_X.head(5)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(adult_X, adult_y, test_size=0.2, random_state=42)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "y_test = y_test['income']\n",
    "sensitive_features_train = X_train['sex']\n",
    "sensitive_features_test = X_test['sex']\n",
    "\n",
    "sensitive_features_train[sensitive_features_train < 0] = 0\n",
    "sensitive_features_train[sensitive_features_train > 0] = 1\n",
    "sensitive_features_train = sensitive_features_train.reset_index(drop=True)\n",
    "\n",
    "sensitive_features_test[sensitive_features_test < 0] = 0\n",
    "sensitive_features_test[sensitive_features_test > 0] = 1\n",
    "sensitive_features_test = sensitive_features_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Accuracy: \" + str(accuracy_score(y_pred, y_test)))\n",
    "groups, group_metrics, gaps = evaluate_fairness(y_test, y_pred, sensitive_features_test)\n",
    "\n",
    "# Demographic Parity\n",
    "for group in groups:\n",
    "      print(\"P[h(X) = 1 | {}] = {}\".format(group, group_metrics['dp'][group]))\n",
    "print(\"Delta_dp = {}\".format(gaps['dp']))\n",
    "\n",
    "# Equalized Odds\n",
    "for group in groups:\n",
    "    print(\"P[h(X) = 1 | A = {}, Y = 1] = {}\".format(group, group_metrics['eo_y1'][group]))\n",
    "    print(\"P[h(X) = 1 | A = {}, Y = 0] = {}\".format(group, group_metrics['eo_y0'][group]))\n",
    "print(\"Delta_eo1 = {}\".format(gaps['eo_y1']))\n",
    "print(\"Delta_eo0 = {}\".format(gaps['eo_y0']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "groups, group_metrics, gaps = evaluate_fairness(y_test, y_pred, sensitive_features_test)\n",
    "\n",
    "print(\"Random Forest Accuracy: \" + str(accuracy_score(y_pred, y_test)))\n",
    "\n",
    "# Demographic Parity\n",
    "for group in groups:\n",
    "      print(\"P[h(X) = 1 | {}] = {}\".format(group, group_metrics['dp'][group]))\n",
    "print(\"Delta_dp = {}\".format(gaps['dp']))\n",
    "\n",
    "# Equalized Odds\n",
    "for group in groups:\n",
    "    print(\"P[h(X) = 1 | A = {}, Y = 1] = {}\".format(group, group_metrics['eo_y1'][group]))\n",
    "    print(\"P[h(X) = 1 | A = {}, Y = 0] = {}\".format(group, group_metrics['eo_y0'][group]))\n",
    "print(\"Delta_eo1 = {}\".format(gaps['eo_y1']))\n",
    "print(\"Delta_eo0 = {}\".format(gaps['eo_y0']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Law School Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lawschool_X = pd.read_csv('./data/lawschool_X.csv')\n",
    "lawschool_y = pd.read_csv('./data/lawschool_y.csv')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(lawschool_X, lawschool_y, test_size=0.2, random_state=42)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "y_test = y_test['bar1']\n",
    "sensitive_features_train = X_train['race7']\n",
    "sensitive_features_test = X_test['race7']\n",
    "\n",
    "sensitive_features_train[sensitive_features_train < 0] = 0\n",
    "sensitive_features_train[sensitive_features_train > 0] = 1\n",
    "sensitive_features_train = sensitive_features_train.reset_index(drop=True)\n",
    "\n",
    "sensitive_features_test[sensitive_features_test < 0] = 0\n",
    "sensitive_features_test[sensitive_features_test > 0] = 1\n",
    "sensitive_features_test = sensitive_features_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Accuracy: \" + str(accuracy_score(y_pred, y_test)))\n",
    "groups, group_metrics, gaps = evaluate_fairness(y_test, y_pred, sensitive_features_test)\n",
    "\n",
    "# Demographic Parity\n",
    "for group in groups:\n",
    "      print(\"P[h(X) = 1 | {}] = {}\".format(group, group_metrics['dp'][group]))\n",
    "print(\"Delta_dp = {}\".format(gaps['dp']))\n",
    "\n",
    "# Equalized Odds\n",
    "for group in groups:\n",
    "    print(\"P[h(X) = 1 | A = {}, Y = 1] = {}\".format(group, group_metrics['eo_y1'][group]))\n",
    "    print(\"P[h(X) = 1 | A = {}, Y = 0] = {}\".format(group, group_metrics['eo_y0'][group]))\n",
    "print(\"Delta_eo1 = {}\".format(gaps['eo_y1']))\n",
    "print(\"Delta_eo0 = {}\".format(gaps['eo_y0']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "groups, group_metrics, gaps = evaluate_fairness(y_test, y_pred, sensitive_features_test)\n",
    "\n",
    "print(\"Random Forest Accuracy: \" + str(accuracy_score(y_pred, y_test)))\n",
    "\n",
    "# Demographic Parity\n",
    "for group in groups:\n",
    "      print(\"P[h(X) = 1 | {}] = {}\".format(group, group_metrics['dp'][group]))\n",
    "print(\"Delta_dp = {}\".format(gaps['dp']))\n",
    "\n",
    "# Equalized Odds\n",
    "for group in groups:\n",
    "    print(\"P[h(X) = 1 | A = {}, Y = 1] = {}\".format(group, group_metrics['eo_y1'][group]))\n",
    "    print(\"P[h(X) = 1 | A = {}, Y = 0] = {}\".format(group, group_metrics['eo_y0'][group]))\n",
    "print(\"Delta_eo1 = {}\".format(gaps['eo_y1']))\n",
    "print(\"Delta_eo0 = {}\".format(gaps['eo_y0']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Communities Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_X = pd.read_csv('./data/communities_X.csv')\n",
    "communities_y = pd.read_csv('./data/communities_y.csv')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(communities_X, communities_y, test_size=0.2, random_state=42)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "y_test = y_test['ViolentCrimesPerPop']\n",
    "sensitive_features_train = X_train['majority_white']\n",
    "sensitive_features_test = X_test['majority_white']\n",
    "\n",
    "sensitive_features_train[sensitive_features_train < 0] = 0\n",
    "sensitive_features_train[sensitive_features_train > 0] = 1\n",
    "sensitive_features_train = sensitive_features_train.reset_index(drop=True)\n",
    "\n",
    "sensitive_features_test[sensitive_features_test < 0] = 0\n",
    "sensitive_features_test[sensitive_features_test > 0] = 1\n",
    "sensitive_features_test = sensitive_features_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Accuracy: \" + str(accuracy_score(y_pred, y_test)))\n",
    "groups, group_metrics, gaps = evaluate_fairness(y_test, y_pred, sensitive_features_test)\n",
    "\n",
    "# Demographic Parity\n",
    "for group in groups:\n",
    "      print(\"P[h(X) = 1 | {}] = {}\".format(group, group_metrics['dp'][group]))\n",
    "print(\"Delta_dp = {}\".format(gaps['dp']))\n",
    "\n",
    "# Equalized Odds\n",
    "for group in groups:\n",
    "    print(\"P[h(X) = 1 | A = {}, Y = 1] = {}\".format(group, group_metrics['eo_y1'][group]))\n",
    "    print(\"P[h(X) = 1 | A = {}, Y = 0] = {}\".format(group, group_metrics['eo_y0'][group]))\n",
    "print(\"Delta_eo1 = {}\".format(gaps['eo_y1']))\n",
    "print(\"Delta_eo0 = {}\".format(gaps['eo_y0']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "groups, group_metrics, gaps = evaluate_fairness(y_test, y_pred, sensitive_features_test)\n",
    "\n",
    "print(\"Random Forest Accuracy: \" + str(accuracy_score(y_pred, y_test)))\n",
    "\n",
    "# Demographic Parity\n",
    "for group in groups:\n",
    "      print(\"P[h(X) = 1 | {}] = {}\".format(group, group_metrics['dp'][group]))\n",
    "print(\"Delta_dp = {}\".format(gaps['dp']))\n",
    "\n",
    "# Equalized Odds\n",
    "for group in groups:\n",
    "    print(\"P[h(X) = 1 | A = {}, Y = 1] = {}\".format(group, group_metrics['eo_y1'][group]))\n",
    "    print(\"P[h(X) = 1 | A = {}, Y = 0] = {}\".format(group, group_metrics['eo_y0'][group]))\n",
    "print(\"Delta_eo1 = {}\".format(gaps['eo_y1']))\n",
    "print(\"Delta_eo0 = {}\".format(gaps['eo_y0']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_X.head[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
